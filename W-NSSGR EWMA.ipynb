{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IC Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:01<00:00, 162.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Run Length: 193.4022\n",
      "Standard Deviation: 264.9671780337331\n",
      "5th Percentile: 17.0\n",
      "95th Percentile: 700.0\n",
      "Median: 97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "m = 100\n",
    "sim = 10000\n",
    "n = 5\n",
    "exp_w = (n * (n + m + 1)) / 2\n",
    "stdev_w = np.sqrt(n * m * (n + m + 1) / 12)\n",
    "lambda_ = 0.05\n",
    "Le = 2.23\n",
    "L_SSGR =  3\n",
    "# df = 5\n",
    "df = 20\n",
    "# shape_param = 1  # Shape parameter for the gamma distribution\n",
    "shape_param = 6.058  # Shape parameter for the gamma distribution\n",
    "scale_param = 0.33  # Scale parameter for the gamma distribution\n",
    "\n",
    "# Control Limits\n",
    "LCL = exp_w - Le * stdev_w * np.sqrt(lambda_ / (2 - lambda_))\n",
    "UCL = exp_w + Le * stdev_w * np.sqrt(lambda_ / (2 - lambda_))\n",
    "\n",
    "# Simulating Phase I and Phase II\n",
    "run_lengths = []\n",
    "previous_run_length = None  # Store the previous nonconforming run length\n",
    "total_runs = []\n",
    "for i in tqdm(range(sim)):\n",
    "    zi_1 = exp_w  # Phase I mean as starting EWMA value\n",
    "    # xi = np.random.normal(0, 1, m)  # Phase I data Normal\n",
    "    # xi = np.random.standard_t(df, m)  # Phase I data t\n",
    "    xi = np.random.gamma(shape_param, scale_param, m) + 5.18 # Phase I data Gamma\n",
    "    # xi=(xi-shape_param)/np.sqrt(shape_param)\n",
    "    count = 0\n",
    "    signaled = False\n",
    "    total_run = 0\n",
    "    while not signaled:\n",
    "        count += 1\n",
    "        total_run += 1\n",
    "        # yi = np.random.normal(0, 1, n)  # Phase II data\n",
    "        # yi = np.random.standard_t(df, n)  # Phase II data t\n",
    "        yi = np.random.gamma(shape_param, scale_param, n) + 5.18  # Phase II data Gamma\n",
    "        # yi=(yi-shape_param)/np.sqrt(shape_param)\n",
    "        comb = np.concatenate((xi, yi))\n",
    "        ranks = np.argsort(np.argsort(comb)) + 1  # Rank calculation\n",
    "        W = ranks[-n:].sum()  # Sum of ranks for new sample\n",
    "\n",
    "        # Calculate W-EWMA\n",
    "        zi = lambda_ * W + (1 - lambda_) * zi_1\n",
    "        zi_1 = zi\n",
    "        # Check control limits and evaluate run length\n",
    "        if zi >= UCL or zi <= LCL:\n",
    "            if previous_run_length is None:\n",
    "                # Check if the first nonconforming group is below the threshold\n",
    "                if count <= L_SSGR:\n",
    "                    run_lengths.append(count)\n",
    "                    total_runs.append(total_run)\n",
    "                    signaled = True\n",
    "            elif previous_run_length <= L_SSGR and count <= L_SSGR:\n",
    "                run_lengths.append(count)\n",
    "                total_runs.append(total_run)\n",
    "                signaled = True\n",
    "\n",
    "            previous_run_length = count\n",
    "            count = 0  # Reset count after nonconforming group and no signal\n",
    "\n",
    "run_lengths = np.array(total_runs)\n",
    "print(f\"Mean Run Length: {run_lengths.mean()}\")\n",
    "print(f\"Standard Deviation: {run_lengths.std()}\")\n",
    "print(f\"5th Percentile: {np.percentile(run_lengths, 5)}\")\n",
    "print(f\"95th Percentile: {np.percentile(run_lengths, 95)}\")\n",
    "print(f\"Median: {np.percentile(run_lengths, 50)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# np.random.seed(123)\n",
    "# Parameters\n",
    "m = 100\n",
    "sim = 10000\n",
    "n = 5\n",
    "exp_w = (n * (n + m + 1)) / 2\n",
    "stdev_w = np.sqrt(n * m * (n + m + 1) / 12)\n",
    "lambda_ = 0.5\n",
    "Le = 1.863       # For lamba=0.5\n",
    "# Le = 2.234         # For lambda=0.05\n",
    "L_SSGR = 3\n",
    "df = 5\n",
    "# df = 20\n",
    "# shape_param = 1  # Shape parameter for the gamma distribution\n",
    "shape_param = 15  # Shape parameter for the gamma distribution\n",
    "scale_param = 1  # Scale parameter for the gamma distribution\n",
    "\n",
    "# Control Limits\n",
    "LCL = exp_w - Le * stdev_w * np.sqrt(lambda_ / (2 - lambda_))\n",
    "UCL = exp_w + Le * stdev_w * np.sqrt(lambda_ / (2 - lambda_))\n",
    "\n",
    "# Delta values\n",
    "deltas = np.arange(0, 3.25, 0.25)\n",
    "\n",
    "# DataFrame to store results\n",
    "results = pd.DataFrame(columns=['Delta', 'ARL', 'SDRL', 'MDRL'])\n",
    "previous_run_length = None\n",
    "\n",
    "for delta in deltas:\n",
    "    print(delta)\n",
    "    total_runs = []\n",
    "    run_lengths = []\n",
    "    previous_run_length = None\n",
    "    for i in tqdm(range(sim)):\n",
    "        zi_1 = exp_w  # Phase I mean as starting EWMA value\n",
    "        # xi = np.random.normal(0, 1, m)  # Phase I data Normal\n",
    "        xi = np.random.standard_t(df, m)  # Phase I data t\n",
    "        # xi = np.random.gamma(shape_param, scale_param, m)  # Phase I data Gamma\n",
    "        # xi=(xi-shape_param)/np.sqrt(shape_param)\n",
    "        count = 0\n",
    "        signaled = False\n",
    "        total_run = 0\n",
    "        while not signaled:\n",
    "            count += 1\n",
    "            total_run += 1\n",
    "            # yi = np.random.normal(delta, 1, n)  # Phase II data\n",
    "            yi = np.random.standard_t(df, n) + delta  # Phase II data t\n",
    "            # y1 = np.random.gamma(shape_param, scale_param, n)  # Phase II data Gamma\n",
    "            # yi=(y1-shape_param)/np.sqrt(shape_param) + delta\n",
    "            comb = np.concatenate((xi, yi))\n",
    "            ranks = np.argsort(np.argsort(comb)) + 1\n",
    "            W = ranks[-n:].sum()\n",
    "\n",
    "            zi = lambda_ * W + (1 - lambda_) * zi_1  # Calculate W-EWMA\n",
    "            zi_1 = zi\n",
    "\n",
    "            if zi >= UCL or zi <= LCL:\n",
    "                if previous_run_length is None:\n",
    "                # Check if the first nonconforming group is below the threshold\n",
    "                    if count <= L_SSGR:\n",
    "                        run_lengths.append(count)\n",
    "                        total_runs.append(total_run)\n",
    "                        signaled = True\n",
    "                elif previous_run_length <= L_SSGR and count <= L_SSGR:\n",
    "                    run_lengths.append(count)\n",
    "                    total_runs.append(total_run)\n",
    "                    signaled = True\n",
    "                    \n",
    "                previous_run_length = count\n",
    "                count = 0  # Reset count after nonconforming group\n",
    "\n",
    "    # Calculate metrics\n",
    "    run_lengths = np.array(total_runs)\n",
    "    ARL = run_lengths.mean()\n",
    "    SDRL = run_lengths.std()\n",
    "    MDRL = np.percentile(run_lengths, 50)\n",
    "\n",
    "    # Append to results\n",
    "    results_row = pd.DataFrame({'Delta': [delta], 'ARL': [ARL], 'SDRL': [SDRL], 'MDRL': [MDRL]})\n",
    "    results = pd.concat([results, results_row], ignore_index=True)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pandas\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "m = 100\n",
    "sim = 10000\n",
    "n = 5\n",
    "exp_w = (n * (n + m + 1)) / 2\n",
    "stdev_w = numpy.sqrt(n * m * (n + m + 1) / 12)\n",
    "L_SSGR = 3\n",
    "# df = 5\n",
    "df = 20\n",
    "# shape_param = 1  # Shape parameter for the gamma distribution\n",
    "shape_param = 15  # Shape parameter for the gamma distribution\n",
    "scale_param = 1  # Scale parameter for the gamma distribution\n",
    "\n",
    "# Delta values\n",
    "deltas = numpy.arange(0, 3.25, 0.25)\n",
    "\n",
    "# Parameters for lambda and Le\n",
    "lambda_values = [0.05, 0.5]\n",
    "Le_values = [2.234, 1.863]\n",
    "\n",
    "# DataFrame to store results\n",
    "results = pandas.DataFrame(columns=['Delta', 'ARL (0.5)', 'ARL (0.05)'])\n",
    "\n",
    "for lambda_, Le in zip(lambda_values, Le_values):\n",
    "    # Control Limits\n",
    "    LCL = exp_w - Le * stdev_w * numpy.sqrt(lambda_ / (2 - lambda_))\n",
    "    UCL = exp_w + Le * stdev_w * numpy.sqrt(lambda_ / (2 - lambda_))\n",
    "    \n",
    "    column_name = f'ARL ({lambda_})'\n",
    "    \n",
    "    for delta in deltas:\n",
    "        print(f\"Delta: {delta}, Lambda: {lambda_}\")\n",
    "        total_runs = []\n",
    "        run_lengths = []\n",
    "        previous_run_length = None\n",
    "        \n",
    "        for i in tqdm(range(sim)):\n",
    "            zi_1 = exp_w  # Phase I mean as starting EWMA value\n",
    "            \n",
    "            # Phase I data (t-distribution standardized to zero mean and unit variance)\n",
    "            # xi = numpy.random.normal(0, 1, m)  # Phase I data Normal\n",
    "            # xi = numpy.random.standard_t(df, m)  # Phase I data t\n",
    "            xi = numpy.random.gamma(shape_param, scale_param, m)  # Phase I data Gamma\n",
    "            xi=(xi-shape_param)/numpy.sqrt(shape_param)\n",
    "            \n",
    "            count = 0\n",
    "            signaled = False\n",
    "            total_run = 0\n",
    "            \n",
    "            while not signaled:\n",
    "                count += 1\n",
    "                total_run += 1\n",
    "                \n",
    "                # Phase II data (t-distribution standardized and shifted by delta)\n",
    "                # yi = numpy.random.normal(delta, 1, n)  # Phase II data\n",
    "                # yi = numpy.random.standard_t(df, n) + delta  # Phase II data t\n",
    "                y1 = numpy.random.gamma(shape_param, scale_param, n)  # Phase II data Gamma\n",
    "                yi=(y1-shape_param)/numpy.sqrt(shape_param) + delta\n",
    "                \n",
    "                comb = numpy.concatenate((xi, yi))\n",
    "                ranks = numpy.argsort(numpy.argsort(comb)) + 1\n",
    "                W = ranks[-n:].sum()\n",
    "    \n",
    "                zi = lambda_ * W + (1 - lambda_) * zi_1  # Calculate W-EWMA\n",
    "                zi_1 = zi\n",
    "    \n",
    "                if zi >= UCL or zi <= LCL:\n",
    "                    if previous_run_length is None:\n",
    "                        # Check if the first nonconforming group is below the threshold\n",
    "                        if count <= L_SSGR:\n",
    "                            run_lengths.append(count)\n",
    "                            total_runs.append(total_run)\n",
    "                            signaled = True\n",
    "                    elif previous_run_length <= L_SSGR and count <= L_SSGR:\n",
    "                        run_lengths.append(count)\n",
    "                        total_runs.append(total_run)\n",
    "                        signaled = True\n",
    "    \n",
    "                    previous_run_length = count\n",
    "                    count = 0  # Reset count after nonconforming group\n",
    "    \n",
    "        # Calculate metrics\n",
    "        run_lengths = numpy.array(total_runs)\n",
    "        ARL = run_lengths.mean()\n",
    "        \n",
    "        # Store results\n",
    "        if delta in results['Delta'].values:\n",
    "            results.loc[results['Delta'] == delta, column_name] = ARL\n",
    "        else:\n",
    "            new_row = pandas.DataFrame({'Delta': [delta], column_name: [ARL]})\n",
    "            results = pandas.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Format the columns as (ARL_0.5, ARL_0.05)\n",
    "results['ARL'] = results.apply(lambda row: f\"({row['ARL (0.05)']:.2f}, {row['ARL (0.5)']:.2f})\", axis=1)\n",
    "results = results[['Delta', 'ARL']]\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
